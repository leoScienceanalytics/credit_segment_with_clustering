{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Importando bibliotecas\n","import pandas as pd\n","import numpy as np\n","from sklearn import cluster\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import Normalizer\n","from sklearn.cluster import KMeans\n","import plotly.graph_objects as go\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn import metrics\n","from sklearn.metrics import calinski_harabasz_score\n","from sklearn.metrics import adjusted_rand_score\n","from sklearn.metrics import pairwise_distances\n","from itertools import combinations\n","import seaborn as sns\n","from sklearn import preprocessing\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dados = pd.read_csv('creditcustomersegmentation.csv')\n","dados.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dados = dados.drop(['CUST_ID', 'TENURE'], axis=1)\n","dados"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["missing = dados.isna().sum()\n","missing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dados.fillna(dados.median(), inplace=True)\n","missing = dados.isna().sum()\n","missing"]},{"cell_type":"markdown","metadata":{},"source":["Qual modelo de normalização usar? \n","\n","Função StandardScaler() --> Útil para dados que estão em diferentes escalas e possuem diferentes unidades de medida.\n","\n","Função Normalizer() --> Útil para dados que possuem escalas similares, porém possuem unidades de medidas diferentes.\n","\n","Nesse caso, deve utilizar o Normalizer()."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["values = Normalizer().fit_transform(dados.values)\n","values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kmeans = KMeans(n_clusters=5, n_init=10, max_iter=300)\n","#Forçando o algoritmo a entregar 10x os mesmos valores\n","#Algoritmo itera 300x\n","y_pred = kmeans.fit_predict(values)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = pd.DataFrame(y_pred)\n","dados['Cluster'] = y_pred\n","dados['Cluster']"]},{"cell_type":"markdown","metadata":{},"source":["Etapa de validação dos clusters.\n","\n","Critérios de Validação:\n","\n","Compactação --> Quão próximos estão os pontos em um mesmo cluster.\n","\n","Separação --> Qual bem separados os pontos de clusters diferentes estão.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Coeficiente do Silhouette \n","\n","s = (b - a)/ (max(a, b))\n","\n","a --> Distância média entre um ponto específico de um cluster, em relação aos outros pontos do mesmo cluster.\n","\n","b --> Distância média entro o ponto e todos os outros pontos do cluster mais próximo.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Métrica do Silhoutette\n","labels = kmeans.labels_\n","silhouette = metrics.silhouette_score(values, labels, metric='euclidean')\n","silhouette"]},{"cell_type":"markdown","metadata":{},"source":["Coeficiente de Davies-Bouldin\n","\n","DB = 1/K * SOMA de 1 a K (máx i!=j --> Rij)\n","\n","Rij --> Medidas de similaridade entre dois clusters i e j\n","\n","Rij = (Si + Sj) / dij\n","\n","S --> Distância média entre cada ponto do clusters e o seu centroide.\n","\n","d --> Distância entre centroides dos clusters.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Métrica Davies-Bouldin\n","dbs = metrics.davies_bouldin_score(values, labels)\n","dbs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Métrica Calinski\n","calinski = metrics.calinski_harabasz_score(values, labels)\n","calinski"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def clustering_algorithm(n_clusters, dataset):\n","    kmeans = KMeans(n_clusters, n_init=10, max_iter=300)\n","    labels = kmeans.fit_predict(dataset)\n","    s = metrics.silhouette_score(dataset, labels, metric='euclidean')\n","    dbs = metrics.davies_bouldin_score(dataset, labels)\n","    calinski = metrics.calinski_harabasz_score(dataset, labels)\n","    return s, dbs, calinski"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["s1, dbs1, calinski1 = clustering_algorithm(3, values)\n","print(s1, dbs1, calinski1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["s2, dbs2, calinski2 = clustering_algorithm(5, values)\n","print(s2, dbs2, calinski2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["s3, dbs3, calinski3 = clustering_algorithm(10, values)\n","print(s3, dbs3, calinski3)"]},{"cell_type":"markdown","metadata":{},"source":["Devido o contexto do problema, deve ser escolhido 5 clusters, pois com n_clusters = 5, temos o maior número para esse indicador, que é mais relevante."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["random_data = np.random.rand(8950, 16)\n","s, dbs, calinski = clustering_algorithm(5, random_data)\n","print(s, dbs, calinski)\n","print(s2, dbs2, calinski2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["set1, set2, set3 = np.array_split(values, 3)\n","s1, dbs1, calinski1 = clustering_algorithm(5, set1)\n","s2, dbs2, calinski2 = clustering_algorithm(5, set2)\n","s3, dbs3, calinski3 = clustering_algorithm(5, set3)\n","\n","print(s1, dbs1, calinski1)\n","print(s2, dbs2, calinski2)\n","print(s3, dbs3, calinski3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.scatter(dados['PURCHASES'], dados['PAYMENTS'], c=labels, s=5, cmap='rainbow')\n","plt.xlabel('Payments')\n","plt.ylabel('Purchases')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dados.groupby('Cluster').describe()"]},{"cell_type":"markdown","metadata":{},"source":["Agora deve-se analisar a variância dos centróides para certos atributos. \n","\n","Vamos pegar 5 clusters e um atritbuto, e vammos ver como esse valor se comporta dentro dos 5 clusters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["centroids = kmeans.cluster_centers_\n","print(centroids)"]},{"cell_type":"markdown","metadata":{},"source":["Precisamos encontrar os atributos que mais variam entre clusters.\n","\n","Para assim encontrarmos especificidades entre os cluster."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Calculando a variância em cada um dos atributos\n","max = len(centroids[0])\n","for i in range(max):\n","    print(dados.columns.values[i], '\\n{:.4f}'.format(centroids[:, i].var()))"]},{"cell_type":"markdown","metadata":{},"source":["BALANCE 0.0224\n","\n","PURCHASE 0.0197\n","\n","CASH_ADVANCE 0.0226\n","\n","MINIMUM_PAYMENTS 0.0546\n","\n","CREDIT_LIMIT 0.0360\n","\n","PAYMENTS 0.0279"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["colunas = ['BALANCE', 'PURCHASES', 'CASH_ADVANCE', 'CREDIT_LIMIT', 'PAYMENTS']\n","description = dados.groupby('Cluster')[colunas]\n","n_clients = description.size()\n","description = description.mean()\n","description['n_clients'] = n_clients\n","description"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dados.groupby('Cluster')['PRC_FULL_PAYMENT'].describe()"]},{"cell_type":"markdown","metadata":{},"source":["Análise de Clusters"]},{"cell_type":"markdown","metadata":{},"source":["Cluster 0: Clientes que gastam muito com saques. Pagadores medianos.\n","\n","Cluster 1: Clientes que gastam pouco. Possuem o maior limite. São bons pagadores. Maior número de clientes.\n","\n","Cluster 2: Clientes com menor limite. Não são bons pagadores. Menor quantidade de clientes.\n","\n","Cluster 3: Clientes que mais gastam, com foco em saque. São os piores pagadores. Boa quantidade de clientes.\n","\n","Cluster 4: Clientes que gastam muito com compras. Melhores pagadores."]},{"cell_type":"markdown","metadata":{},"source":["Cluster 0: Cliente Padrão --> Gastam uma certa quantidade e pagam de uma forma mediana.\n","\n","\n","Cluster 1: Cliente Premium --> Poder aquisitivo alto, porém não realizam muitas compras.\n","\n","\n","Cluster 2: Clientes Ruins --> Não possuem limites altos por quê não pagam seus cartões.\n","\n","\n","Cluster 3: Clientes Ruins --> Conseguem sacar, porém atrasam o pagamento.\n","\n","\n","Cluster 4: Clientes Premium --> Realizam compras e pagam, pode-se dizer que possuem poder aquisitivo alto."]},{"cell_type":"markdown","metadata":{},"source":["Com base na análise decide-se trabalhar uma estratégia de marketing em cima do Cluster 1.\n","\n","Vai ser utilizado o Teste AB, onde irá ser separado dois grupos: Controle e Teste.\n","\n","Controle --> Não irá ser submetido ao teste\n","Teste --> Será testado.\n","\n","Será validado com o tempo.\n","\n","Caso o resultado do objetivo seja o mesmo para os dois, talvez a estrátegia de mkt não seja tão efetiva"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":2}
